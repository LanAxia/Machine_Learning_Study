{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mat = np.matrix([\n",
    "    [0, 0, 1, 1, 1, 0, 1, 1, 1, 0], \n",
    "    [1, 3, 2, 1, 2 ,1, 1, 1, 3, 2], \n",
    "    [3, 1, 2, 3, 3, 2, 2, 1, 1, 1], \n",
    "])\n",
    "y_mat = np.matrix([\n",
    "    -1, -1, -1, -1, -1, -1, 1, 1, -1, -1, \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Round 1\n",
      "The normalized w: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
      "The Classifier:\n",
      "1 0 | None\n",
      "\n",
      "The error is 0.200\n",
      "The alpha is 0.693\n",
      "The weak classifier's prediction result: \n",
      "[[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "The whole bag of classifications's result: \n",
      "[[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "------------------------------\n",
      "Round 2\n",
      "The normalized w: [0.062, 0.062, 0.062, 0.062, 0.062, 0.062, 0.25, 0.25, 0.062, 0.062]\n",
      "The Classifier:\n",
      "3 2 | 1\n",
      "\n",
      "The error is 0.188\n",
      "The alpha is 0.733\n",
      "The weak classifier's prediction result: \n",
      "[[ 1. -1. -1.  1. -1.  1.  1.  1. -1. -1.]]\n",
      "The whole bag of classifications's result: \n",
      "[[ 1. -1. -1.  1. -1.  1.  1.  1. -1. -1.]]\n",
      "------------------------------\n",
      "Round 3\n",
      "The normalized w: [0.167, 0.038, 0.038, 0.167, 0.038, 0.167, 0.154, 0.154, 0.038, 0.038]\n",
      "The Classifier:\n",
      "3 2 | 1\n",
      "\n",
      "The error is 0.269\n",
      "The alpha is 0.499\n",
      "The weak classifier's prediction result: \n",
      "[[-1.  1. -1. -1. -1. -1. -1.  1.  1.  1.]]\n",
      "The whole bag of classifications's result: \n",
      "[[-1. -1. -1. -1. -1. -1. -1.  1. -1. -1.]]\n",
      "------------------------------\n",
      "Round 4\n",
      "The normalized w: [0.114, 0.071, 0.026, 0.114, 0.026, 0.114, 0.286, 0.105, 0.071, 0.071]\n",
      "The Classifier:\n",
      "0 | 1\n",
      "\n",
      "The error is 0.238\n",
      "The alpha is 0.582\n",
      "The weak classifier's prediction result: \n",
      "[[-1. -1.  1.  1.  1. -1.  1.  1.  1. -1.]]\n",
      "The whole bag of classifications's result: \n",
      "[[-1. -1. -1.  1. -1. -1.  1.  1. -1. -1.]]\n",
      "------------------------------\n",
      "Round 5\n",
      "The normalized w: [0.075, 0.047, 0.055, 0.239, 0.055, 0.075, 0.188, 0.069, 0.15, 0.047]\n",
      "The Classifier:\n",
      "1 0 | None\n",
      "\n",
      "The error is 0.257\n",
      "The alpha is 0.532\n",
      "The weak classifier's prediction result: \n",
      "[[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "The whole bag of classifications's result: \n",
      "[[-1. -1. -1. -1. -1. -1. -1.  1. -1. -1.]]\n",
      "------------------------------\n",
      "Round 6\n",
      "The normalized w: [0.05, 0.032, 0.037, 0.161, 0.037, 0.05, 0.365, 0.135, 0.101, 0.032]\n",
      "The Classifier:\n",
      "3 | 2 1\n",
      "\n",
      "The error is 0.251\n",
      "The alpha is 0.545\n",
      "The weak classifier's prediction result: \n",
      "[[-1.  1.  1. -1. -1.  1.  1.  1.  1.  1.]]\n",
      "The whole bag of classifications's result: \n",
      "[[-1. -1. -1. -1. -1. -1.  1.  1. -1. -1.]]\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 单层树桩分类器\n",
    "def stump_classify(mat, dim, thresh_val, ascending):\n",
    "    result = np.ones((1, mat.shape[1]))\n",
    "    x = mat[dim]\n",
    "    for i in range(len(x)):\n",
    "        if ascending is True:\n",
    "            result[mat[dim, :] <= thresh_val] = -1\n",
    "        else:\n",
    "            result[mat[dim, :] > thresh_val] = -1\n",
    "    return result\n",
    "\n",
    "# 找到最优树桩（允许预测结果 全部取1和全部取-1）\n",
    "def build_stump(x_mat, y_mat, w):\n",
    "    m, n = x_mat.shape\n",
    "    best_stump = []\n",
    "    best_acc = -1\n",
    "    best_result = np.matrix([0])\n",
    "    w_sum = np.sum(w)\n",
    "    for dim in range(m):\n",
    "        unique_vals = sorted(set(np.array(x_mat)[dim]))\n",
    "        for val_floor, val_ceil in zip([unique_vals[0] - 0.1] + unique_vals, unique_vals + [unique_vals[0] + 0.1]): # 这里不能全部取负\n",
    "            ascending = True\n",
    "            thresh_val = (val_floor + val_ceil) / 2\n",
    "            pred_result = stump_classify(x_mat, dim, thresh_val, ascending=True)\n",
    "            accuracy = np.sum(np.multiply((pred_result == y_mat), w))\n",
    "            if accuracy < w_sum / 2:\n",
    "                ascending = False\n",
    "                accuracy = w_sum - accuracy\n",
    "                pred_result = - pred_result\n",
    "            if accuracy > best_acc:\n",
    "                best_stump = [dim, thresh_val, ascending]\n",
    "                best_acc = accuracy\n",
    "                best_result = pred_result\n",
    "    return best_stump, best_acc, best_result\n",
    "\n",
    "# 计算矩阵之和\n",
    "def sum_mat(mat_lst):\n",
    "    result = mat_lst[0].copy()\n",
    "    if len(mat_lst) > 1:\n",
    "        for mat in mat_lst[1:]:\n",
    "            result += mat\n",
    "    return result\n",
    "\n",
    "# adaboost主算法\n",
    "def adaboost(x_mat, y_mat, max_classifier_num=30):\n",
    "    weak_classifiers = []\n",
    "    weak_classifiers_result = []\n",
    "    m, n = x_mat.shape\n",
    "    w = np.matrix(np.array([1 / n] * n).reshape(1, n))\n",
    "    for i in range(max_classifier_num):\n",
    "        print('------------------------------')\n",
    "        print('Round {}'.format(i + 1))\n",
    "        print('The normalized w: {}'.format(str(list(np.round(np.array(w), 3)[0]))))\n",
    "        weak_classifier, accuracy, weak_classifier_result = build_stump(x_mat, y_mat, w)\n",
    "        weak_classifiers.append(weak_classifier)\n",
    "        err = 1 - accuracy\n",
    "        alpha = 0.5 * np.log((1 - err)/err)\n",
    "        weak_classifiers_result.append(alpha * weak_classifier_result)\n",
    "        print('The Classifier:')\n",
    "        dim, thresh_val, direction = weak_classifier\n",
    "        classifier_lst = sorted(list(set(np.array(x_mat)[dim])) + [thresh_val], reverse=not direction)\n",
    "        classifier_lst[classifier_lst.index(thresh_val)] = '|'\n",
    "        classifier_lst = map(str, classifier_lst)\n",
    "        classifier_str = ' '.join(classifier_lst)\n",
    "        if classifier_str[-1] == '|':\n",
    "            classifier_str += ' None'\n",
    "        if classifier_str[0] == '|':\n",
    "            classifier_str = ['None '] + classifier_str\n",
    "        print(classifier_str)\n",
    "        print('\\nThe error is {:.03f}'.format(err))\n",
    "        print('The alpha is {:.03f}'.format(alpha))\n",
    "        print('The weak classifier\\'s prediction result: \\n{}'.format(str(np.sign(weak_classifier_result))))\n",
    "        print('The whole bag of classifications\\'s result: \\n{}'.format(str(np.sign(sum_mat(weak_classifiers_result)))))\n",
    "\n",
    "        if np.average(np.multiply(sum_mat(weak_classifiers_result), y_mat) > 0) == 1:\n",
    "            print('------------------------------')\n",
    "            return weak_classifiers\n",
    "        \n",
    "        w = np.multiply(w, np.exp(- alpha * np.multiply(np.sign(weak_classifier_result), y_mat)))\n",
    "        w = w / np.sum(w)\n",
    "    print('------------------------------')\n",
    "    return weak_classifiers\n",
    "\n",
    "\n",
    "classifiers = adaboost(x_mat, y_mat, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 2.5, 3]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(set(np.array(x_mat)[2])) + [2.5], reverse=not True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(np.array(x_mat)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单层树桩分类器\n",
    "def stump_classify(mat, dim, thresh_val, ascending):\n",
    "    result = np.ones((1, mat.shape[1]))\n",
    "    x = mat[dim]\n",
    "    for i in range(len(x)):\n",
    "        if ascending is True:\n",
    "            result[mat[dim, :] <= thresh_val] = -1\n",
    "        else:\n",
    "            result[mat[dim, :] > thresh_val] = -1\n",
    "    return result\n",
    "\n",
    "# 找到最优树桩（不允许预测结果全部取1和全部取-1）\n",
    "def build_stump(x_mat, y_mat, w):\n",
    "    m, n = x_mat.shape\n",
    "    best_stump = []\n",
    "    best_acc = -1\n",
    "    best_result = np.matrix([0])\n",
    "    w_sum = np.sum(w)\n",
    "    for dim in range(m):\n",
    "        unique_vals = sorted(set(np.array(x_mat)[dim]))\n",
    "        for val_floor, val_ceil in zip(unique_vals[:-1], unique_vals[1:]): # 这里不能全部取负\n",
    "            ascending = True\n",
    "            thresh_val = (val_floor + val_ceil) / 2\n",
    "            pred_result = stump_classify(x_mat, dim, thresh_val, ascending=True)\n",
    "            accuracy = np.sum(np.multiply((pred_result == y_mat), w))\n",
    "            if accuracy < w_sum / 2:\n",
    "                ascending = False\n",
    "                accuracy = w_sum - accuracy\n",
    "                pred_result = - pred_result\n",
    "            if accuracy > best_acc:\n",
    "                best_stump = [dim, thresh_val, ascending]\n",
    "                best_acc = accuracy\n",
    "                best_result = pred_result\n",
    "    return best_stump, best_acc, best_result\n",
    "\n",
    "# 计算矩阵之和\n",
    "def sum_mat(mat_lst):\n",
    "    result = mat_lst[0].copy()\n",
    "    if len(mat_lst) > 1:\n",
    "        for mat in mat_lst[1:]:\n",
    "            result += mat\n",
    "    return result\n",
    "\n",
    "# adaboost主算法\n",
    "def adaboost(x_mat, y_mat, max_classifier_num=30):\n",
    "    weak_classifiers = []\n",
    "    weak_classifiers_result = []\n",
    "    m, n = x_mat.shape\n",
    "    w = np.matrix(np.array([1 / n] * n).reshape(1, n))\n",
    "    for i in range(max_classifier_num):\n",
    "        weak_classifier, accuracy, weak_classifier_result = build_stump(x_mat, y_mat, w)\n",
    "        weak_classifiers.append(weak_classifier)\n",
    "        err = 1 - accuracy\n",
    "        alpha = 0.5 * np.log((1 - err)/err)\n",
    "        weak_classifiers_result.append(alpha * weak_classifier_result)\n",
    "\n",
    "        if np.average(np.multiply(sum_mat(weak_classifiers_result), y_mat) > 0) == 1:\n",
    "            return weak_classifiers\n",
    "        \n",
    "        w = np.multiply(w, np.exp(- alpha * np.multiply(np.sign(weak_classifier_result), y_mat)))\n",
    "        w = w / np.sum(w)\n",
    "    return weak_classifiers\n",
    "\n",
    "len(adaboost(x_mat, y_mat, 100))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5b0090f9c919a3d6ed76b4d901c1278536bd598516fd1e0ec891bddcf94e37ee"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
